<!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1"><meta name="format-detection" content="telephone=no"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="black"><meta name="keywords" content="LSM, Mia's blog"><meta name="description" content="生活总是需要不断的跌倒，再不断的爬起来，这就是生活。"><title>【第一期AI夏令营丨自然语言处理】任务一：文本二分类_&amp;&amp;Baseline代码分析及改进 | Mia's blog</title><meta name="google-site-verification" content="HPcpCEPE_TQ7LlH-LAToYJleDQ7ydr0Mgiw95TQ5GNQ"><meta name="msvalidate.01" content="9C903B945C2FE1FB1A111163F0C32703"><meta name="theme-color" content="#54bcff"><link rel="manifest" href="../../../../manifest.json?v=1.5.4"><link rel="icon" href="../../../../images/icons/Lv-16.png?v=1.5.4" type="image/png" sizes="16x16"><link rel="icon" href="../../../../images/icons/Lv-32.png?v=1.5.4" type="image/png" sizes="32x32"><link rel="alternate" href="../../../../atom.xml" type="application/atom+xml"><link rel="dns-prefetch" href="https://cdn.jsdelivr.net"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@4.7.0/css/font-awesome.min.css" type="text/css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/gitalk@latest/dist/gitalk.min.css" type="text/css"><link rel="stylesheet" href="../../../../css/index.css?v=1.5.4"><link rel="dns-prefetch" href="https://www.googletagmanager.com"><link rel="dns-prefetch" href="https://hm.baidu.com"><link rel="dns-prefetch" href="https://tajs.qq.com"><script src="https://www.googletagmanager.com/gtag/js?id=UA-156048106-1" async=""></script><script>if (window.location.hostname !== 'localhost') {
  window.dataLayer = window.dataLayer || [];
  function gtag(){ dataLayer.push(arguments); }
  gtag('js', new Date());
  gtag('config', 'UA-156048106-1');
}</script><script>var _hmt = _hmt || [];
(function() {
  var hm = document.createElement('script');
  hm.src = 'https://hm.baidu.com/hm.js?3df607e8ce8da7ad737b9205f02966ee';
  hm.async = true;

  if (false) { hm.setAttribute('data-pjax', ''); }

  var s = document.getElementsByTagName('script')[0]; 
  s.parentNode.insertBefore(hm, s);
})();</script><script>(function() {
  var hm = document.createElement('script');
  hm.src = 'https://tajs.qq.com/stats?sId=undefined';
  hm.async = true;

  if (false) { hm.setAttribute('data-pjax', ''); }

  var s = document.getElementsByTagName('script')[0]; 
  s.parentNode.insertBefore(hm, s);
})();</script><script>var Stun = window.Stun || {};
var CONFIG = {
  root: '/',
  algolia: undefined,
  fontawesome: {"prefix":"fa"},
  sidebar: {"offsetTop":"30px","renderTocDepth":4},
  header: {"scrollDownIcon":true},
  back2top: {"enable":true},
  reward: false,
  fancybox: false,
  zoom_image: {"enable":true,"mask_color":"rgba(0,0,0,0.6)"},
  gallery_waterfall: undefined,
  lazyload: undefined,
  pjax: undefined,
  external_link: {"icon":{"enable":true,"name":"external-link"}},
  shortcuts: {"switch_post":false},
  prompt: {"copy_success":"复制成功","copy_error":"复制失败","creative_commons":"知识共享","copy_button":"点击复制"}
};

window.CONFIG = CONFIG;</script></head><body><div class="container" id="container"><header class="header" id="header"><div class="header-inner"><nav class="header-nav"><div class="header-nav-inner"><div class="header-nav-btn fa fa-bars"></div><div class="header-nav-menu"><div class="header-nav-menu-item"><a class="header-nav-menu-item__a" href="/"><i class="fa fa-home"></i>首页</a></div><div class="header-nav-menu-item"><a class="header-nav-menu-item__a" href="javascript:;" target="_blank" rel="noopener"><i class="fa fa-paint-brush"></i>文章</a><div class="header-nav-submenu"><div class="header-nav-menu-item"><a class="header-nav-menu-item__a" href="/archives/"><i class="fa fa-folder-open"></i>归档</a></div><div class="header-nav-menu-item"><a class="header-nav-menu-item__a" href="/categories/"><i class="fa fa-th"></i>分类</a></div><div class="header-nav-menu-item"><a class="header-nav-menu-item__a" href="/tags/"><i class="fa fa-tags"></i>标签</a></div></div></div><div class="header-nav-menu-item"><a class="header-nav-menu-item__a" href="/about/"><i class="fa fa-user"></i>关于</a></div><div class="header-nav-menu-item"><a class="header-nav-menu-item__a" href="/friends/"><i class="fa fa-hand-spock-o"></i>友链</a></div></div><div class="header-nav-search"><i class="fa fa-search"></i><span>搜索</span></div></div></nav><div class="header-info"><div class="header-info-inner"><div class="header-info-title">Mia's blog</div><div class="header-info-subtitle">留意身边的美好</div></div><div class="header-info-scrolldown"><i class="fa fa-angle-down header-info-scrolldown__icon"></i></div></div></div></header><main class="main" id="main"><div class="main-inner"><div class="content-wrap" id="content-wrap"><div class="content"><div class="post"><header class="post-header"><h1 class="post-header-title">【第一期AI夏令营丨自然语言处理】任务一：文本二分类_&amp;&amp;Baseline代码分析及改进</h1><div class="post-header-meta"><span class="post-header-meta-create"><i class="fa fa-calendar-o"></i><span>发表于 </span><span>2023-10-24</span></span><span class="post-header-meta-update"><i class="fa fa-calendar-check-o"></i><span>更新于 </span><span>2023-10-24</span></span><span class="post-header-meta-word-count"><i class="fa fa-file-word-o"></i><span>字数统计 </span><span>1.6k</span></span><span class="post-header-meta-reading-time"><i class="fa fa-clock-o"></i><span>阅读时长 </span><span>11m</span></span><span class="post-header-meta-reading-count"><i class="fa fa-eye"></i><span>阅读次数 </span><span id="busuanzi_value_page_pv"></span></span></div></header><div class="post-body"><p>﻿<a name="tZJcy"></a></p>
<h2 id="一、问题分析"><span class="heading-link">一、问题分析</span></h2><p><strong>从论文标题、摘要作者等信息，判断该论文是否属于医学领域的文献。</strong><br>针对文本分类任务，可以提供两种实践思路，一种是使用传统的特征提取方法（如TF-IDF/BOW）结合机器学习模型，另一种是使用预训练的BERT模型进行建模。使用特征提取 + 机器学习的思路步骤如下：</p>
<ol>
<li><strong>数据预处理</strong> ：首先，对文本数据进行预处理，包括文本清洗（如去除特殊字符、标点符号）、分词等操作。可以使用常见的NLP工具包（如NLTK或spaCy）来辅助进行预处理。</li>
<li><strong>特征提取</strong>：使用TF-IDF（词频-逆文档频率）或BOW（词袋模型）方法将文本转换为向量表示。TF-IDF可以计算文本中词语的重要性，而BOW则简单地统计每个词语在文本中的出现次数。可以使用scikit-learn库的TfidfVectorizer或CountVectorizer来实现特征提取。</li>
<li><strong>构建训练集和测试集</strong>：将预处理后的文本数据分割为训练集和测试集，确保数据集的样本分布均匀。</li>
<li><strong>选择机器学习模型</strong>：根据实际情况选择适合的机器学习模型，如朴素贝叶斯、支持向量机（SVM）、随机森林等。这些模型在文本分类任务中表现良好。可以使用scikit-learn库中相应的分类器进行模型训练和评估。</li>
<li><strong>模型训练和评估</strong>：使用训练集对选定的机器学习模型进行训练，然后使用测试集进行评估。评估指标可以选择准确率、精确率、召回率、F1值等。</li>
<li><strong>调参优化</strong>：如果模型效果不理想，可以尝试调整特征提取的参数（如词频阈值、词袋大小等）或机器学习模型的参数，以获得更好的性能。</li>
</ol>
<p><a name="GflxY"></a></p>
<h2 id="二、Baseline代码分析"><span class="heading-link">二、Baseline代码分析</span></h2><figure class="highlight python"><div class="table-container"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 导入pandas用于读取表格数据</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line"><span class="comment"># 导入BOW（词袋模型），可以选择将CountVectorizer替换为TfidfVectorizer（TF-IDF（词频-逆文档频率）），注意上下文要同时修改，亲测后者效果更佳</span></span><br><span class="line"><span class="keyword">from</span> sklearn.feature_extraction.text <span class="keyword">import</span> CountVectorizer</span><br><span class="line"></span><br><span class="line"><span class="comment"># 导入LogisticRegression回归模型</span></span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line"></span><br><span class="line"><span class="comment"># 过滤警告消息</span></span><br><span class="line"><span class="keyword">from</span> warnings <span class="keyword">import</span> simplefilter</span><br><span class="line"><span class="keyword">from</span> sklearn.exceptions <span class="keyword">import</span> ConvergenceWarning</span><br><span class="line">simplefilter(<span class="string">"ignore"</span>, category=ConvergenceWarning)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 读取数据集</span></span><br><span class="line">train = pd.read_csv(<span class="string">'/home/aistudio/data/data231041/train.csv'</span>)</span><br><span class="line">train[<span class="string">'title'</span>] = train[<span class="string">'title'</span>].fillna(<span class="string">''</span>)  <span class="comment"># 缺失值填充为一个空字符串</span></span><br><span class="line">train[<span class="string">'abstract'</span>] = train[<span class="string">'abstract'</span>].fillna(<span class="string">''</span>)</span><br><span class="line"></span><br><span class="line">test = pd.read_csv(<span class="string">'/home/aistudio/data/data231041/test.csv'</span>)</span><br><span class="line">test[<span class="string">'title'</span>] = test[<span class="string">'title'</span>].fillna(<span class="string">''</span>)</span><br><span class="line">test[<span class="string">'abstract'</span>] = test[<span class="string">'abstract'</span>].fillna(<span class="string">''</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 提取文本特征，生成训练集与测试集</span></span><br><span class="line">train[<span class="string">'text'</span>] = train[<span class="string">'title'</span>].fillna(<span class="string">''</span>) + <span class="string">' '</span> +  train[<span class="string">'author'</span>].fillna(<span class="string">''</span>) + <span class="string">' '</span> + train[<span class="string">'abstract'</span>].fillna(<span class="string">''</span>)+ <span class="string">' '</span> + train[<span class="string">'Keywords'</span>].fillna(<span class="string">''</span>)  <span class="comment"># 合并成一行数据</span></span><br><span class="line">test[<span class="string">'text'</span>] = test[<span class="string">'title'</span>].fillna(<span class="string">''</span>) + <span class="string">' '</span> +  test[<span class="string">'author'</span>].fillna(<span class="string">''</span>) + <span class="string">' '</span> + test[<span class="string">'abstract'</span>].fillna(<span class="string">''</span>)+ <span class="string">' '</span> + train[<span class="string">'Keywords'</span>].fillna(<span class="string">''</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">vector = CountVectorizer().fit(train['text']):   它使用了 CountVectorizer 对象对文本数据进行了分词、去除停用词、统计词频等操作，将每个文本转换为一个向量。</span></span><br><span class="line"><span class="string">最后，使用 fit 方法根据训练数据构建词表，并将其保存在 CountVectorizer 对象中，以便后续使用。</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line">vector = CountVectorizer().fit(train[<span class="string">'text'</span>]) <span class="comment"># 输出： CountVectorizer()</span></span><br><span class="line"><span class="comment"># print (vector)</span></span><br><span class="line">train_vector = vector.transform(train[<span class="string">'text'</span>]) <span class="comment"># 每个文本转换为一个向量。这里使用了 transform 方法，是为了将训练数据转换为向量形式</span></span><br><span class="line"><span class="keyword">print</span> (<span class="string">'train_vector'</span>,type(train_vector),train_vector)  <span class="comment"># 输出结果： (0, 2345)	2   意思是 (0, 2345) 2 表示第一个文本中词表中编号为 2345 的单词出现了两次。</span></span><br><span class="line"></span><br><span class="line">feature_names = vector.get_feature_names_out() <span class="comment"># 获取词表中每个单词的名称，然后查找对应编号的单词。</span></span><br><span class="line">print(<span class="string">'feature_names'</span>,feature_names[<span class="number">2345</span>]) <span class="comment"># 查找2345编号的单词为access，在第一个文本中出现两次。</span></span><br></pre></td></tr></tbody></table></div></figure>

<figure class="highlight python"><div class="table-container"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">输出结果如下</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line">train_vector &lt;<span class="class"><span class="keyword">class</span> '<span class="title">scipy</span>.<span class="title">sparse</span>.<span class="title">_csr</span>.<span class="title">csr_matrix</span>'&gt;   <span class="params">(<span class="number">0</span>, <span class="number">1469</span>)</span>	1</span></span><br><span class="line"><span class="class">  <span class="params">(<span class="number">0</span>, <span class="number">2345</span>)</span>	2  # "<span class="params">(<span class="number">0</span>, <span class="number">2345</span>)</span> 2 "表示第一个文本中词表中编号为 2345 的单词出现了两次。</span></span><br><span class="line"><span class="class">  <span class="params">(<span class="number">0</span>, <span class="number">2348</span>)</span>	1</span></span><br><span class="line"><span class="class">  <span class="params">(<span class="number">0</span>, <span class="number">2349</span>)</span>	4</span></span><br><span class="line"><span class="class">  <span class="params">(<span class="number">0</span>, <span class="number">3869</span>)</span>	1</span></span><br><span class="line"><span class="class">  <span class="params">(<span class="number">0</span>, <span class="number">4268</span>)</span>	1</span></span><br><span class="line"><span class="class">  <span class="params">(<span class="number">0</span>, <span class="number">4382</span>)</span>	15</span></span><br><span class="line"><span class="class">  <span class="params">(<span class="number">0</span>, <span class="number">5112</span>)</span>	3</span></span><br><span class="line"><span class="class">  <span class="params">(<span class="number">0</span>, <span class="number">5290</span>)</span>	1</span></span><br><span class="line"><span class="class">  <span class="params">(<span class="number">0</span>, <span class="number">5505</span>)</span>	5</span></span><br><span class="line"><span class="class">  <span class="params">(<span class="number">0</span>, <span class="number">5575</span>)</span>	1</span></span><br><span class="line"><span class="class">  <span class="params">(<span class="number">0</span>, <span class="number">5585</span>)</span>	1</span></span><br><span class="line"><span class="class">  <span class="params">(<span class="number">0</span>, <span class="number">5586</span>)</span>	4</span></span><br><span class="line"><span class="class">  <span class="params">(<span class="number">0</span>, <span class="number">5891</span>)</span>	1</span></span><br><span class="line"><span class="class">  <span class="params">(<span class="number">0</span>, <span class="number">6096</span>)</span>	3</span></span><br><span class="line"><span class="class">  <span class="params">(<span class="number">0</span>, <span class="number">6106</span>)</span>	1</span></span><br><span class="line"><span class="class">  <span class="params">(<span class="number">0</span>, <span class="number">6224</span>)</span>	1</span></span><br><span class="line"><span class="class">  <span class="params">(<span class="number">0</span>, <span class="number">6545</span>)</span>	1</span></span><br><span class="line"><span class="class">  <span class="params">(<span class="number">0</span>, <span class="number">7019</span>)</span>	1</span></span><br><span class="line"><span class="class">  <span class="params">(<span class="number">0</span>, <span class="number">7233</span>)</span>	1</span></span><br><span class="line"><span class="class">  <span class="params">(<span class="number">0</span>, <span class="number">8463</span>)</span>	3</span></span><br><span class="line"><span class="class">   :</span>	:</span><br><span class="line">  (<span class="number">5999</span>, <span class="number">66915</span>)	<span class="number">1</span></span><br><span class="line">  (<span class="number">5999</span>, <span class="number">67033</span>)	<span class="number">1</span></span><br><span class="line">feature_names access   <span class="comment"># # 查找2345编号的单词为access，在第一个文本中出现两次。</span></span><br></pre></td></tr></tbody></table></div></figure>

<p><strong>于是我去数据集中的第一个文本中进行验证发现，access确实是出现了两次（如下图所示）。</strong></p>
<p><img src="https://img-blog.csdnimg.cn/img_convert/f5617264b160ea92a0dccb2d31f08ff1.png#averageHue=#f3eee7&amp;clientId=u41e8680b-ee9d-4&amp;from=paste&amp;height=429&amp;id=u368707f7&amp;originHeight=429&amp;originWidth=797&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=37609&amp;status=done&amp;style=none&amp;taskId=u69171e0b-ba32-404d-b9d3-21033749c39&amp;title=&amp;width=797" alt="image.png"></p>
<p><strong>引入模型及标签预测：</strong></p>
<figure class="highlight python"><div class="table-container"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">test_vector = vector.transform(test[<span class="string">'text'</span>])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 引入模型</span></span><br><span class="line">model = LogisticRegression()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 开始训练，这里可以考虑修改默认的batch_size与epoch来取得更好的效果</span></span><br><span class="line">model.fit(train_vector, train[<span class="string">'label'</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 利用模型对测试集label标签进行预测</span></span><br><span class="line">test[<span class="string">'label'</span>] = model.predict(test_vector)</span><br><span class="line">print(<span class="string">"test['label']"</span>,test[<span class="string">'label'</span>])</span><br><span class="line">print(<span class="string">'test\n:'</span>,test)</span><br><span class="line"><span class="comment"># 生成任务一推测结果</span></span><br><span class="line">test[[<span class="string">'uuid'</span>, <span class="string">'Keywords'</span>, <span class="string">'label'</span>]].to_csv(<span class="string">'submit_task1.csv'</span>, index=<span class="literal">None</span>)</span><br></pre></td></tr></tbody></table></div></figure>

<figure class="highlight python"><div class="table-container"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">输出结果如下：</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line">test[<span class="string">'label'</span>] <span class="number">0</span>       <span class="number">1</span></span><br><span class="line"><span class="number">1</span>       <span class="number">0</span></span><br><span class="line"><span class="number">2</span>       <span class="number">0</span></span><br><span class="line"><span class="number">3</span>       <span class="number">0</span></span><br><span class="line"><span class="number">4</span>       <span class="number">0</span></span><br><span class="line">       ..</span><br><span class="line"><span class="number">2353</span>    <span class="number">1</span></span><br><span class="line"><span class="number">2354</span>    <span class="number">0</span></span><br><span class="line"><span class="number">2355</span>    <span class="number">0</span></span><br><span class="line"><span class="number">2356</span>    <span class="number">0</span></span><br><span class="line"><span class="number">2357</span>    <span class="number">1</span></span><br><span class="line">Name: label, Length: <span class="number">2358</span>, dtype: int64</span><br><span class="line">test:</span><br><span class="line">uuid                   title            author  abstract  Keywords text  label  </span><br><span class="line"><span class="number">0</span>        <span class="number">0</span>  Monitoring Changes <span class="keyword">in</span> ...  </span><br><span class="line"><span class="number">1</span>        <span class="number">1</span>  Source Printer Classification ...     ...        ...    ...    ...     </span><br><span class="line"><span class="number">2</span>        <span class="number">2</span>  Plasma-processed CoSn/RGO   </span><br><span class="line"><span class="number">3</span>        <span class="number">3</span>  Immediate Antiretroviral ...   </span><br><span class="line"><span class="number">4</span>        <span class="number">4</span>  Design <span class="keyword">and</span> analysis of an ...</span><br><span class="line">[<span class="number">2358</span> rows x <span class="number">7</span> columns]</span><br></pre></td></tr></tbody></table></div></figure>

<p><a name="MuGq1"></a></p>
<h2 id="三、代码修改"><span class="heading-link">三、代码修改</span></h2><p>在跑通Baseline代码后，得到的分数为：<strong>0.99384</strong>。 以下是尝试的几种修改策略。</p>
<ol>
<li><p><strong>将CountVectorizer替换为TfidfVectorizer</strong></p>
<p>未设置参数时得到的评分为：<strong>0.97655</strong><br>设置参数后得到的评分为：<strong>0.98171</strong></p>
</li>
</ol>
<figure class="highlight python"><div class="table-container"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用TfidfVectorizer进行文本向量化</span></span><br><span class="line"><span class="keyword">from</span> sklearn.feature_extraction.text <span class="keyword">import</span> TfidfVectorizer</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义TfidfVectorizer，设置参数，例如调整ngram范围，最大特征数等</span></span><br><span class="line"><span class="comment"># vector = TfidfVectorizer().fit(train['text'])  # 未设置参数时得到的评分为：0.97655	</span></span><br><span class="line">vector = TfidfVectorizer(ngram_range=(<span class="number">1</span>, <span class="number">2</span>), max_features=<span class="number">5000</span>).fit(train[<span class="string">'text'</span>]) <span class="comment"># 设置参数后得到的评分为：0.98171</span></span><br><span class="line">train_vector = vector.transform(train[<span class="string">'text'</span>])</span><br><span class="line">test_vector = vector.transform(test[<span class="string">'text'</span>])</span><br></pre></td></tr></tbody></table></div></figure>

<ol start="2">
<li><p><strong>尝试使用SVM模型</strong></p>
<p>使用SVM模型得到的评分为：<strong>0.99489</strong></p>
</li>
</ol>
<figure class="highlight python"><div class="table-container"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.svm <span class="keyword">import</span> SVC</span><br><span class="line"></span><br><span class="line"><span class="comment"># 尝试使用SVM模型</span></span><br><span class="line">model = SVC(kernel=<span class="string">'linear'</span>)</span><br><span class="line">model.fit(train_vector, train[<span class="string">'label'</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 进行预测</span></span><br><span class="line">test[<span class="string">'label'</span>] = model.predict(test_vector)</span><br></pre></td></tr></tbody></table></div></figure>

<ol start="3">
<li><p><strong>尝试使用随机森林模型</strong></p>
<p>使用随机森林模型得到的评分为：<strong>0.98995</strong></p>
</li>
</ol>
<figure class="highlight python"><div class="table-container"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestClassifier</span><br><span class="line"></span><br><span class="line"><span class="comment"># 尝试使用随机森林模型</span></span><br><span class="line">model = RandomForestClassifier(n_estimators=<span class="number">100</span>)</span><br><span class="line">model.fit(train_vector, train[<span class="string">'label'</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 进行预测</span></span><br><span class="line">test[<span class="string">'label'</span>] = model.predict(test_vector)</span><br></pre></td></tr></tbody></table></div></figure>

<h2 id="【参考】"><span class="heading-link">【参考】</span></h2><p><span class="external-link"><a href="https://aistudio.baidu.com/aistudio/projectdetail/6522950?sUid=377372&amp;shared=1&amp;ts=1689827255213" target="_blank" rel="noopener">手把手打一场NLP赛事</a><i class="fa fa-external-link"></i></span><br>赛事链接：<span class="external-link"><a href="https://challenge.xfyun.cn/topic/info?type=abstract-of-the-paper" target="_blank" rel="noopener">基于论文摘要的文本分类与关键词抽取挑战赛</a><i class="fa fa-external-link"></i></span></p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script></div><footer class="post-footer"><div class="post-copyright"><div class="post-copyright-author"><span class="post-copyright-author-name">本文作者: </span><span class="post-copyright-author-value"><a href="https://lvshaomei.github.io">LSM</a></span></div><div class="post-copyright-link"><span class="post-copyright-link-name">本文链接: </span><span class="post-copyright-link-value"><a href="https://lvshaomei.github.io/2023/10/24/%E3%80%90%E7%AC%AC%E4%B8%80%E6%9C%9FAI%E5%A4%8F%E4%BB%A4%E8%90%A5%E4%B8%A8%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E3%80%91%E4%BB%BB%E5%8A%A1%E4%B8%80%EF%BC%9A%E6%96%87%E6%9C%AC%E4%BA%8C%E5%88%86%E7%B1%BB-Baseline%E4%BB%A3%E7%A0%81%E5%88%86%E6%9E%90%E5%8F%8A%E6%94%B9%E8%BF%9B/">https://lvshaomei.github.io/2023/10/24/%E3%80%90%E7%AC%AC%E4%B8%80%E6%9C%9FAI%E5%A4%8F%E4%BB%A4%E8%90%A5%E4%B8%A8%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E3%80%91%E4%BB%BB%E5%8A%A1%E4%B8%80%EF%BC%9A%E6%96%87%E6%9C%AC%E4%BA%8C%E5%88%86%E7%B1%BB-Baseline%E4%BB%A3%E7%A0%81%E5%88%86%E6%9E%90%E5%8F%8A%E6%94%B9%E8%BF%9B/</a></span></div><div class="post-copyright-notice"><span class="post-copyright-notice-name">版权声明: </span><span class="post-copyright-notice-value">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh-cn" rel="external nofollow" target="_blank">BY-NC-SA</a> 许可协议。转载请注明出处！</span></div></div><nav class="paginator"><div class="paginator-post"><div class="paginator-post-prev"><a class="paginator-post-prev__a" href="../%E3%80%90%E7%AC%AC%E4%B8%80%E6%9C%9FAI%E5%A4%8F%E4%BB%A4%E8%90%A5%E4%B8%A8%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E3%80%91%E4%BD%BF%E7%94%A8BERT%E6%A8%A1%E5%9E%8B%E8%A7%A3%E5%86%B3%E9%97%AE%E9%A2%98/%E3%80%90%E7%AC%AC%E4%B8%80%E6%9C%9FAI%E5%A4%8F%E4%BB%A4%E8%90%A5%E4%B8%A8%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E3%80%91%E4%BD%BF%E7%94%A8BERT%E6%A8%A1%E5%9E%8B%E8%A7%A3%E5%86%B3%E9%97%AE%E9%A2%98/"><i class="fa fa-chevron-left"></i><span>【第一期AI夏令营丨自然语言处理】使用BERT模型解决问题</span></a></div><div class="paginator-post-next"><a class="paginator-post-next__a" href="../%E3%80%90%E7%AC%AC%E4%B8%80%E6%9C%9FAI%E5%A4%8F%E4%BB%A4%E8%90%A5%E4%B8%A8%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E3%80%91%E8%B5%9B%E4%BA%8B%E4%BF%A1%E6%81%AF/"><span>【第一期AI夏令营丨自然语言处理】赛事信息</span><i class="fa fa-chevron-right"></i></a></div></div></nav></footer></div></div><div class="comments" id="comments"><div id="gitalk-container"></div></div></div><aside class="sidebar" id="sidebar"><div class="sidebar-inner"><div class="sidebar-nav"><span class="sidebar-nav-toc current">文章目录</span><span class="sidebar-nav-ov">站点概览</span></div><section class="sidebar-toc"><div><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#一、问题分析"><span class="toc-number">1.</span> <span class="toc-text">一、问题分析</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#二、Baseline代码分析"><span class="toc-number">2.</span> <span class="toc-text">二、Baseline代码分析</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#三、代码修改"><span class="toc-number">3.</span> <span class="toc-text">三、代码修改</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#【参考】"><span class="toc-number">4.</span> <span class="toc-text">【参考】</span></a></li></ol></div></section><!-- ov = overview --><section class="sidebar-ov hide"><div class="sidebar-ov-author"><div class="sidebar-ov-author__avatar"><img class="sidebar-ov-author__avatar_img" src="/images/banner/labia.jpeg" alt="avatar"></div><p class="sidebar-ov-author__p">The Harder You Work, The Luckier You Will Be.</p></div><div class="sidebar-ov-social"><a class="sidebar-ov-social__item" href="https://github.com/Lvshaomei/Lvshaomei.github.io" target="_blank" rel="noopener" data-popover="Github" data-popover-pos="up"><i class="sidebar-ov-social__item--icon fa fa-github"></i></a><a class="sidebar-ov-social__item" href="https://segmentfault.com/u/lvlv_5e182fd7c6adc" target="_blank" rel="noopener" data-popover="思否" data-popover-pos="up"><span class="sidebar-ov-social__item--logo">sf</span></a><a class="sidebar-ov-social__item" href="https://www.zhihu.com/people/fa-liang-jian-shao/activities" target="_blank" rel="noopener" data-popover="知乎" data-popover-pos="up"><span class="sidebar-ov-social__item--logo">�</span></a><a class="sidebar-ov-social__item" href="https://juejin.im/user/5da86e3d5188257948602ace" target="_blank" rel="noopener" data-popover="social.juejin" data-popover-pos="up"><span class="sidebar-ov-social__item--logo">�</span></a></div><div class="sidebar-ov-feed"><span class="sidebar-ov-feed-rss"><a class="sidebar-ov-feed-rss__a" href="../../../../atom.xml" target="_blank" rel="noopener"><i class="sidebar-ov-feed-rss__a--icon fa fa-rss"></i><span>RSS </span><span>订阅</span></a></span></div><div class="sidebar-ov-state"></div><div class="sidebar-ov-cc"><a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh-cn" target="_blank" rel="noopener" data-popover="知识共享" data-popover-pos="up"><img src="../../../../images/cc-by-nc-sa.svg" alt="知识共享"></a></div></section><div class="sidebar-reading"><div class="sidebar-reading-info"><span>你已阅读了 </span><span class="sidebar-reading-info-num">0</span></div><div class="sidebar-reading-line"></div></div></div></aside><div class="clearfix"></div></div></main><footer class="footer" id="footer"><div class="footer-inner"><div><span>&copy; 2023</span><span class="fa fa-heart footer-icon"></span><span>LSM.</span></div><div><span>由 <a href="http://hexo.io/" title="hexo" target="_blank" rel="noopener">hexo</a> 强力驱动</span><span> v4.0.0.</span><span class="separator">|</span><span>主题 - <a href="https://github.com/liuyib/hexo-theme-stun/" title="stun" target="_blank" rel="noopener">stun</a></span><span> v1.5.4.</span></div><div class="busuanzi"><span class="busuanzi-site_uv"><i class="fa fa-user"></i><span>访问人数 </span><span id="busuanzi_value_site_uv"></span></span><span class="separator">|</span><span class="busuanzi-site_pv"><i class="fa fa-eye"></i><span>浏览总量 </span><span id="busuanzi_value_site_pv"></span></span><script src="https://cdn.jsdelivr.net/gh/sukkaw/busuanzi@latest/bsz.pure.mini.js" async></script></div></div></footer><div class="loading-bar" id="loading-bar"><div class="progress"></div></div><div class="back2top" id="back2top"><i class="back2top-icon fa fa-rocket"></i></div></div><div class="search-mask"></div><div class="search-popup"><span class="search-close"></span><div class="search-input"><input placeholder="搜索文章（支持多关键词，请用空格分隔）"></div><div class="search-results"></div></div><script src="https://cdn.jsdelivr.net/npm/jquery@v3.4.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-animate@1.5.2/velocity.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-animate@1.5.2/velocity.ui.min.js"></script><script src="https://cdn.jsdelivr.net/npm/ribbon.js@latest/dist/ribbon.min.js" size="120" alpha="0.6" zIndex="-1"></script><script src="https://cdn.jsdelivr.net/gh/theme-next/theme-next-canvas-nest@latest/canvas-nest.min.js" color="243,81,151" opacity="0.5" count="100" zIndex="-2"></script><script>window.addEventListener('DOMContentLoaded', function () {
  $('.header-nav-search').on('click', function (e) {
    e.stopPropagation();

    $('body').css('overflow', 'hidden');
    $('.search-popup')
      .addClass('show')
      .velocity('stop')
      .velocity('transition.expandIn', {
        duration: 300,
        complete: function () {
          $('.search-popup input').focus();
        }
      });
    $('.search-mask')
      .velocity('stop')
      .velocity('transition.fadeIn', {
        duration: 300
      });

    initSearch();
  });

  $('.search-mask, .search-close').on('click', function () {
    closeSearch();
  });

  $(document).on('keydown', function (e) {
    // Escape <=> 27
    if (e.keyCode === Stun.utils.codeToKeyCode('Escape')) {
      closeSearch();
    }
  });

  var isXML = true;
  var search_path = 'search.xml';

  if (!search_path) {
    search_path = 'search.xml';
  } else if (/json$/i.test(search_path)) {
    isXML = false;
  }

  var path = '/' + search_path;

  function initSearch() {
    $.ajax({
      url: path,
      dataType: isXML ? 'xml' : 'json',
      async: true,
      success: function (res) {
        var datas = isXML ? $('entry', res).map(function () {
          // 将 XML 转为 JSON
          return {
            title: $('title', this).text(),
            content: $('content', this).text(),
            url: $('url', this).text()
          };
        }).get() : res;

        var $input = $('.search-input input');
        var $result = $('.search-results');

        // 搜索对象（标题、内容）的权重，影响显示顺序
        var WEIGHT = { title: 100, content: 1 };

        var searchPost = function () {
          var searchText = $input.val().toLowerCase().trim();
          // 根据空白字符分隔关键字
          var keywords = searchText.split(/[\s]+/);
          // 搜索结果
          var matchPosts = [];

          // 有多个关键字时，将原文字整个保存下来
          if (keywords.length > 1) {
            keywords.push(searchText);
          }

          // 防止未输入字符时搜索
          if (searchText.length > 0) {
            datas.forEach(function (data) {
              var isMatch  = false;

              // 没有标题的文章使用预设的 i18n 变量代替
              var title = (data.title && data.title.trim()) || '( 文章无标题 )';
              var titleLower = title && title.toLowerCase();
              // 删除 HTML 标签 和 所有空白字符
              var content = data.content && data.content.replace(/<[^>]+>/g, '');
              var contentLower = content && content.toLowerCase();
              // 删除重复的 /
              var postURL = data.url && decodeURI(data.url).replace(/\/{2,}/g, '/');

              // 标题中匹配到的关键词
              var titleHitSlice = [];
              // 内容中匹配到的关键词
              var contentHitSlice = [];

              keywords.forEach(function (keyword) {
                /**
                  * 获取匹配的关键词的索引
                  * @param {String} keyword 要匹配的关键字
                  * @param {String} text 原文字
                  * @param {Boolean} caseSensitive 是否区分大小写
                  * @param {Number} weight 匹配对象的权重。权重大的优先显示
                  * @return {Array}
                  */
                function getIndexByword (word, text, caseSensitive, weight) {
                  if (!word || !text) return [];

                  var startIndex = 0; // 每次匹配的开始索引
                  var index = -1;     // 匹配到的索引值
                  var result = [];    // 匹配结果

                  if (!caseSensitive) {
                    word = word.toLowerCase();
                    text = text.toLowerCase();
                  }

                  while((index = text.indexOf(word, startIndex)) !== -1) {
                    var hasMatch = false;

                    // 索引位置相同的关键词，保留长度较长的
                    titleHitSlice.forEach(function (hit) {
                      if (hit.index === index && hit.word.length < word.length) {
                        hit.word = word;
                        hasMatch = true;
                      }
                    });
                    startIndex = index + word.length;
                    !hasMatch && result.push({ index: index, word: word, weight: weight });
                  }

                  return result;
                }

                titleHitSlice = titleHitSlice.concat(getIndexByword(keyword, titleLower, false, WEIGHT.title));
                contentHitSlice = contentHitSlice.concat(getIndexByword(keyword, contentLower, false, WEIGHT.content));
              });

              var hitTitle = titleHitSlice.length;
              var hitContent = contentHitSlice.length;

              if (hitTitle > 0 || hitContent > 0) {
                isMatch = true;
              }

              if (isMatch) {
                ;[titleHitSlice, contentHitSlice].forEach(function (hit) {
                  // 按照匹配文字的索引的递增顺序排序
                  hit.sort(function (left, right) {
                    return left.index - right.index;
                  });
                });

                /**
                  * 给文本中匹配到的关键词添加标记，从而进行高亮显示
                  * @param {String} text 原文本
                  * @param {Array} hitSlice 匹配项的索引信息
                  * @param {Number} start 开始索引
                  * @param {Number} end 结束索引
                  * @return {String}
                  */
                function highlightKeyword (text, hitSlice, start, end) {
                  if (!text || !hitSlice || !hitSlice.length) return;

                  var result = '';
                  var startIndex = start;
                  var endIndex = end;

                  hitSlice.forEach(function (hit) {
                    if (hit.index < startIndex) return;

                    var hitWordEnd = hit.index + hit.word.length;

                    result += text.slice(startIndex, hit.index);
                    result += '<b>' + text.slice(hit.index, hitWordEnd) + '</b>';
                    startIndex = hitWordEnd;
                  });
                  result += text.slice(startIndex, endIndex);

                  return result;
                }

                var postData = {};
                // 文章总的搜索权重
                var postWeight = titleHitSlice.length * WEIGHT.title + contentHitSlice.length * WEIGHT.content;
                // 标记匹配关键词后的标题
                var postTitle = highlightKeyword(title, titleHitSlice, 0, title.length) || title;
                // 标记匹配关键词后的内容
                var postContent;
                // 显示内容的长度
                var SHOW_WORD_LENGTH = 200;
                // 命中关键词前的字符显示长度
                var SHOW_WORD_FRONT_LENGTH = 20;
                var SHOW_WORD_END_LENGTH = SHOW_WORD_LENGTH - SHOW_WORD_FRONT_LENGTH;

                // 截取匹配的第一个字符，前后共 200 个字符来显示
                if (contentHitSlice.length > 0) {
                  var firstIndex = contentHitSlice[0].index;
                  var start = firstIndex > SHOW_WORD_FRONT_LENGTH ? firstIndex - SHOW_WORD_FRONT_LENGTH : 0;
                  var end = firstIndex + SHOW_WORD_END_LENGTH;

                  postContent = highlightKeyword(content, contentHitSlice, start, end);
                } else { // 未匹配到内容，直接截取前 200 个字符来显示
                  postContent = content.slice(0, SHOW_WORD_LENGTH);
                }

                postData.title = postTitle;
                postData.content = postContent;
                postData.url = postURL;
                postData.weight = postWeight;
                matchPosts.push(postData);
              }
            });
          }

          var resultInnerHtml = '';

          if (matchPosts.length) {
            // 按权重递增的顺序排序，使权重大的优先显示
            matchPosts.sort(function (left, right) {
              return right.weight - left.weight;
            });

            resultInnerHtml += '<ul>';
            matchPosts.forEach(function (post) {
              resultInnerHtml += '<li><a class="search-results-title" href="' + post.url + '">';
              resultInnerHtml += post.title;
              resultInnerHtml += '</a><div class="search-results-content">';
              resultInnerHtml += post.content;
              resultInnerHtml += '</div></li>';
            });
            resultInnerHtml += '</ul>';
          } else {
            resultInnerHtml += '<div class="search-results-none"><i class="fa fa-meh-o"></i></div>';
          }

          $result.html(resultInnerHtml);
        };

        $input.on('input', searchPost);
        $input.on('keypress', function (e) {
          if (e.keyCode === Stun.utils.codeToKeyCode('Enter')) {
            searchPost();
          }
        });
      }
    });
  }

  function closeSearch () {
    $('body').css('overflow', 'auto');
    $('.search-popup')
      .removeClass('show')
      .velocity('stop')
      .velocity('transition.expandOut', {
        duration: 300
      });
    $('.search-mask')
      .velocity('stop')
      .velocity('transition.fadeOut', {
        duration: 300
      });
  }
}, false);</script><script src="https://cdn.jsdelivr.net/gh/sukkaw/busuanzi@latest/bsz.pure.mini.js" async></script><script src="https://cdn.jsdelivr.net/npm/gitalk@latest/dist/gitalk.min.js"></script><script src="https://cdn.jsdelivr.net/npm/js-md5@latest/src/md5.min.js"></script><script>function loadGitalk () {
  if (!document.getElementById('gitalk-container')) {
    return;
  }

  var gitalk = new Gitalk({
    id: md5(window.location.pathname.slice(1)),
    clientID: '23d7b4a6c1b1589b9d9b',
    clientSecret: 'fcbbb62bf5fe3fac81979e69fd71cd637e0c523f',
    repo: 'Lvshaomei.github.io',
    owner: 'Lvshaomei',
    admin: ['Lvshaomei'],
    distractionFreeMode: 'true',
    language: 'zh-CN'
  });

  gitalk.render('gitalk-container');
}

if (false) {
  loadGitalk();
} else {
  window.addEventListener('DOMContentLoaded', loadGitalk, false);
}</script><script src="../../../../js/utils.js?v=1.5.4"></script><script src="../../../../js/stun-boot.js?v=1.5.4"></script><script src="../../../../js/scroll.js?v=1.5.4"></script><script src="../../../../js/header.js?v=1.5.4"></script><script src="../../../../js/sidebar.js?v=1.5.4"></script></body></html>